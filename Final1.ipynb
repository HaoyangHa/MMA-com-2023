{"cells":[{"cell_type":"markdown","metadata":{"id":"HPIikw0qwOEM"},"source":["# Data processing and data analysis"]},{"cell_type":"markdown","metadata":{"id":"kD_lTWoHwOEP"},"source":["## At the very beginning we're going to say how we're going to separate the frozen and refrigerated.\n","To make up for the beginning, do it with a diagram\n","Let's just say that we counted the existing frozen products and refrigerated, frozen is refrigirated and refrigerated is dairy and egg type and type with any meat. Then train a literal model based on the existing refrigerated as well as frozen, and then put the rows with department as missing and other into the model to determine if he is refrigerated or frozen, and finally cleaned up when all the data is categorized with other, refrigerated, and frozen"]},{"cell_type":"markdown","metadata":{"id":"NITkaHawwOEQ"},"source":["## Importing and cleaning up\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-SeNn3p5wOEQ"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import matplotlib as mpl\n","from datetime import datetime\n","import math\n","import warnings\n","import json"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"VYvSIqIowOES","outputId":"4e1e4840-0ee4-4fc9-e935-45032e465296"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>product_id</th>\n","      <th>product_name</th>\n","      <th>aisle_id</th>\n","      <th>aisle</th>\n","      <th>department_id</th>\n","      <th>department</th>\n","      <th>type3</th>\n","      <th>product_code</th>\n","      <th>substitute_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>7</td>\n","      <td>34050</td>\n","      <td>Orange Juice</td>\n","      <td>31</td>\n","      <td>refrigerated</td>\n","      <td>7</td>\n","      <td>beverages</td>\n","      <td>Refrigerated</td>\n","      <td>55</td>\n","      <td>3455</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7</td>\n","      <td>46802</td>\n","      <td>Pineapple Chunks</td>\n","      <td>116</td>\n","      <td>frozen produce</td>\n","      <td>1</td>\n","      <td>frozen</td>\n","      <td>Frozen</td>\n","      <td>41</td>\n","      <td>1899</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>38</td>\n","      <td>11913</td>\n","      <td>Shelled Pistachios</td>\n","      <td>117</td>\n","      <td>nuts seeds dried fruit</td>\n","      <td>19</td>\n","      <td>snacks</td>\n","      <td>Other</td>\n","      <td>41</td>\n","      <td>2751</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>38</td>\n","      <td>18159</td>\n","      <td>Organic Biologique Limes</td>\n","      <td>123</td>\n","      <td>packaged vegetables fruits</td>\n","      <td>4</td>\n","      <td>produce</td>\n","      <td>Refrigerated</td>\n","      <td>66</td>\n","      <td>3088</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>38</td>\n","      <td>4461</td>\n","      <td>Organic Raw Unfiltered Apple Cider Vinegar</td>\n","      <td>19</td>\n","      <td>oils vinegars</td>\n","      <td>13</td>\n","      <td>pantry</td>\n","      <td>Other</td>\n","      <td>11</td>\n","      <td>2798</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   order_id  product_id                                product_name  aisle_id  \\\n","0         7       34050                                Orange Juice        31   \n","1         7       46802                            Pineapple Chunks       116   \n","2        38       11913                          Shelled Pistachios       117   \n","3        38       18159                    Organic Biologique Limes       123   \n","4        38        4461  Organic Raw Unfiltered Apple Cider Vinegar        19   \n","\n","                        aisle  department_id department         type3  \\\n","0                refrigerated              7  beverages  Refrigerated   \n","1              frozen produce              1     frozen        Frozen   \n","2      nuts seeds dried fruit             19     snacks         Other   \n","3  packaged vegetables fruits              4    produce  Refrigerated   \n","4               oils vinegars             13     pantry         Other   \n","\n","   product_code  substitute_group  \n","0            55              3455  \n","1            41              1899  \n","2            41              2751  \n","3            66              3088  \n","4            11              2798  "]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('mma_mart_Final_data.csv')\n","data.head()"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"aQ3dCTRiwOES","outputId":"98501f4f-b3a7-4f84-b546-6b4650156076"},"outputs":[{"ename":"AttributeError","evalue":"'int' object has no attribute 'isnumeric'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[51], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Remove rows with text values in 'aisle_id' and 'department_id'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_cleaned \u001b[38;5;241m=\u001b[39m data[\n\u001b[1;32m----> 3\u001b[0m     (\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maisle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnumeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      4\u001b[0m     (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepartment_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:  x\u001b[38;5;241m.\u001b[39misnumeric()))\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the shape of the cleaned dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m data_cleaned\u001b[38;5;241m.\u001b[39mshape\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n","File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n","Cell \u001b[1;32mIn[51], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Remove rows with text values in 'aisle_id' and 'department_id'\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_cleaned \u001b[38;5;241m=\u001b[39m data[\n\u001b[1;32m----> 3\u001b[0m     (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maisle_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnumeric\u001b[49m())) \u001b[38;5;241m&\u001b[39m\n\u001b[0;32m      4\u001b[0m     (data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepartment_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x:  x\u001b[38;5;241m.\u001b[39misnumeric()))\n\u001b[0;32m      5\u001b[0m ]\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the shape of the cleaned dataset\u001b[39;00m\n\u001b[0;32m      8\u001b[0m data_cleaned\u001b[38;5;241m.\u001b[39mshape\n","\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'isnumeric'"]}],"source":["# Remove rows with text values in 'aisle_id' and 'department_id'\n","data_cleaned = data[\n","    (data['aisle_id'].apply(lambda x: x.isnumeric())) &\n","    (data['department_id'].apply(lambda x:  x.isnumeric()))\n","]\n","\n","# Display the shape of the cleaned dataset\n","data_cleaned.shape"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>aisle</th>\n","      <th>department</th>\n","      <th>product_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [aisle, department, product_name]\n","Index: []"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["grouped_products = data.groupby(['aisle', 'department'])['product_name'].unique().reset_index()\n","grouped_products"]},{"cell_type":"markdown","metadata":{"id":"20BLjMg0wOET"},"source":["## Text vectorization to find substitute "]},{"cell_type":"code","execution_count":40,"metadata":{"id":"-Xd5SL-qwOET","outputId":"a44d4145-1de6-4041-f5c8-e29e1edbc542"},"outputs":[{"ename":"ValueError","evalue":"empty vocabulary; perhaps the documents only contain stop words","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[40], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# 1. 文本向量化\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 将产品名称转换为向量形式\u001b[39;00m\n\u001b[0;32m     15\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m product_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mvectorizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproduct_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# 使用K-means进行聚类\u001b[39;00m\n\u001b[0;32m     19\u001b[0m num_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m  \u001b[38;5;66;03m# 调整为所需的类别数量\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2091\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2084\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_params()\n\u001b[0;32m   2085\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf \u001b[38;5;241m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2086\u001b[0m     norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm,\n\u001b[0;32m   2087\u001b[0m     use_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_idf,\n\u001b[0;32m   2088\u001b[0m     smooth_idf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmooth_idf,\n\u001b[0;32m   2089\u001b[0m     sublinear_tf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msublinear_tf,\n\u001b[0;32m   2090\u001b[0m )\n\u001b[1;32m-> 2091\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tfidf\u001b[38;5;241m.\u001b[39mfit(X)\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1372\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1364\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1365\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1367\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1368\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1369\u001b[0m             )\n\u001b[0;32m   1370\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1372\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[0;32m   1375\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n","File \u001b[1;32mc:\\Users\\11780\\anaconda\\envs\\my_env\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1278\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1276\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[0;32m   1277\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[1;32m-> 1278\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1279\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1280\u001b[0m         )\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indptr[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39miinfo(np\u001b[38;5;241m.\u001b[39mint32)\u001b[38;5;241m.\u001b[39mmax:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n","\u001b[1;31mValueError\u001b[0m: empty vocabulary; perhaps the documents only contain stop words"]}],"source":["import pandas as pd\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.cluster import KMeans\n","from sklearn.metrics.pairwise import cosine_similarity\n","from collections import defaultdict\n","\n","# Load the dataset\n","data = data_cleaned\n","\n","# Remove rows with NaN in 'product_name'\n","data = data.dropna(subset=['product_name'])\n","\n","# 1. 文本向量化\n","# 将产品名称转换为向量形式\n","vectorizer = TfidfVectorizer(max_features=5000)\n","product_vectors = vectorizer.fit_transform(data['product_name'].unique())\n","\n","# 使用K-means进行聚类\n","num_clusters = 100  # 调整为所需的类别数量\n","kmeans = KMeans(n_clusters=num_clusters)\n","product_clusters = kmeans.fit_predict(product_vectors)\n","\n","# 为每个产品分配一个类别标签\n","product_labels = dict(zip(data['product_name'].unique(), product_clusters))\n","\n","# 根据类别标签对产品进行编码\n","data['product_code'] = data['product_name'].map(product_labels)\n","\n","# 2. Based on product similarity\n","# Group products by 'aisle' and 'department'\n","grouped_products = data.groupby(['aisle', 'department'])['product_name'].unique().reset_index()\n","\n","# Initialize TF-IDF vectorizer\n","vectorizer = TfidfVectorizer()\n","\n","# Set a similarity threshold (products with similarity above this threshold are considered similar)\n","similarity_threshold = 0.1\n","\n","# Initialize a dictionary to store the product-to-group mapping\n","product_to_group = defaultdict(int)\n","\n","# Initialize a group counter\n","group_counter = 1\n","\n","# Loop through each product group based on aisle and department\n","for idx, row in grouped_products.iterrows():\n","    # Get the products in the current group\n","    products = row['product_name']\n","\n","    # Vectorize the product names in the current group\n","    tfidf_matrix = vectorizer.fit_transform(products)\n","\n","    # Compute cosine similarity between product names\n","    cosine_sim = cosine_similarity(tfidf_matrix)\n","\n","    # Initialize a set to keep track of products that have already been assigned a group\n","    assigned_products = set()\n","\n","    # Find pairs of products that are similar based on the threshold\n","    for i in range(len(products)):\n","        if products[i] in assigned_products:\n","            continue\n","\n","        # Create a new group for the current product\n","        current_group = group_counter\n","        product_to_group[products[i]] = current_group\n","        assigned_products.add(products[i])\n","\n","        for j in range(i + 1, len(products)):\n","            if cosine_sim[i, j] > similarity_threshold:\n","                product_to_group[products[j]] = current_group\n","                assigned_products.add(products[j])\n","\n","        # Increment the group counter\n","        group_counter += 1\n","\n","# Add a new column to the original dataset to represent the 'substitute_group'\n","data['substitute_group'] = data['product_name'].map(product_to_group)\n","\n","# Save the updated dataset to a new CSV file\n","data.to_csv('updated_dataset1.csv', index=False)\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"O9ASyDKPwOEU"},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_test \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupdated_dataset.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["data_test = pd.read_csv('updated_dataset.csv')"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"QZ72xtSAwOEV","outputId":"6a74c18b-f9ef-411a-f2fb-fbdb57a9a34d"},"outputs":[{"data":{"text/plain":["4160"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Look at how many UNIQUE VALUES the substitutes_group has\n","data_test['substitute_group'].nunique()\n"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"l3RXCG4iwOEV","outputId":"d8bb4783-0c60-4686-97b7-2d9e4ee5ce6c"},"outputs":[{"data":{"text/plain":["7.958173076923077"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["#Look at the average number of unique products per substitute_group\n","data_test.groupby('substitute_group')['product_id'].nunique().mean()\n"]},{"cell_type":"code","execution_count":60,"metadata":{"id":"qhdgELguwOEW","outputId":"bcc4b98d-220e-4603-f58e-a2d887ada496"},"outputs":[{"name":"stdout","output_type":"stream","text":["   product_id substitute_group\n","0        4265           [1000]\n","1        4866           [1000]\n","2       24777           [1000]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>product_id</th>\n","      <th>product_name</th>\n","      <th>aisle_id</th>\n","      <th>aisle</th>\n","      <th>department_id</th>\n","      <th>department</th>\n","      <th>type3</th>\n","      <th>product_code</th>\n","      <th>substitute_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>8073</th>\n","      <td>4240</td>\n","      <td>4866</td>\n","      <td>Chocolate Covered Biscuit Sticks</td>\n","      <td>61</td>\n","      <td>cookies cakes</td>\n","      <td>19</td>\n","      <td>snacks</td>\n","      <td>Other</td>\n","      <td>85</td>\n","      <td>1000</td>\n","    </tr>\n","    <tr>\n","      <th>24440</th>\n","      <td>12760</td>\n","      <td>24777</td>\n","      <td>Original Fudge Sticks</td>\n","      <td>61</td>\n","      <td>cookies cakes</td>\n","      <td>19</td>\n","      <td>snacks</td>\n","      <td>Other</td>\n","      <td>54</td>\n","      <td>1000</td>\n","    </tr>\n","    <tr>\n","      <th>29702</th>\n","      <td>21820</td>\n","      <td>4265</td>\n","      <td>Chocolate Covered Gluten Free Wafer Bites</td>\n","      <td>61</td>\n","      <td>cookies cakes</td>\n","      <td>19</td>\n","      <td>snacks</td>\n","      <td>Other</td>\n","      <td>9</td>\n","      <td>1000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       order_id  product_id                               product_name  \\\n","8073       4240        4866           Chocolate Covered Biscuit Sticks   \n","24440     12760       24777                      Original Fudge Sticks   \n","29702     21820        4265  Chocolate Covered Gluten Free Wafer Bites   \n","\n","       aisle_id          aisle  department_id department  type3  product_code  \\\n","8073         61  cookies cakes             19     snacks  Other            85   \n","24440        61  cookies cakes             19     snacks  Other            54   \n","29702        61  cookies cakes             19     snacks  Other             9   \n","\n","       substitute_group  \n","8073               1000  \n","24440              1000  \n","29702              1000  "]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["#Output data with substitutes_group 1000, procuct_id, and product_name.\n","\n","print(data_test[data_test['substitute_group'] == 1000].groupby('product_id')['substitute_group'].unique().reset_index())\n","data_test[data_test['substitute_group'] == 1000]\n"]},{"cell_type":"markdown","metadata":{"id":"unMe0ZiXwOEW"},"source":["## With alternatives brought in, we're going to say that we're doing a data cleansing, because there will be Nan present"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"THod792lwOEX"},"outputs":[],"source":["data_test_2 = pd.read_csv('updated_dataset.csv')"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"_vtAGMLswOEX","outputId":"0f35595d-9df4-437b-fb69-5a133829bb72"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>product_id</th>\n","      <th>product_name</th>\n","      <th>aisle_id</th>\n","      <th>aisle</th>\n","      <th>department_id</th>\n","      <th>department</th>\n","      <th>type3</th>\n","      <th>product_code</th>\n","      <th>substitute_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>49302</td>\n","      <td>Bulgarian Yogurt</td>\n","      <td>120</td>\n","      <td>yogurt</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>37</td>\n","      <td>4113</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>11109</td>\n","      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n","      <td>108</td>\n","      <td>other creams cheeses</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>68</td>\n","      <td>2948</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>10246</td>\n","      <td>Organic Celery Hearts</td>\n","      <td>83</td>\n","      <td>fresh vegetables</td>\n","      <td>4</td>\n","      <td>produce</td>\n","      <td>Refrigerated</td>\n","      <td>97</td>\n","      <td>1598</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>49683</td>\n","      <td>Cucumber Kirby</td>\n","      <td>83</td>\n","      <td>fresh vegetables</td>\n","      <td>4</td>\n","      <td>produce</td>\n","      <td>Refrigerated</td>\n","      <td>80</td>\n","      <td>1599</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>43633</td>\n","      <td>Lightly Smoked Sardines in Olive Oil</td>\n","      <td>95</td>\n","      <td>canned meat seafood</td>\n","      <td>15</td>\n","      <td>canned goods</td>\n","      <td>Other</td>\n","      <td>47</td>\n","      <td>635</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>786400</th>\n","      <td>99578</td>\n","      <td>38689</td>\n","      <td>Organic Reduced Fat Milk</td>\n","      <td>84</td>\n","      <td>milk</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>68</td>\n","      <td>2539</td>\n","    </tr>\n","    <tr>\n","      <th>786401</th>\n","      <td>99578</td>\n","      <td>47719</td>\n","      <td>Banana Raspberry &amp; Brown Rice Stage 2</td>\n","      <td>92</td>\n","      <td>baby food formula</td>\n","      <td>18</td>\n","      <td>babies</td>\n","      <td>Other</td>\n","      <td>34</td>\n","      <td>106</td>\n","    </tr>\n","    <tr>\n","      <th>786402</th>\n","      <td>99578</td>\n","      <td>17949</td>\n","      <td>Mild Cheddar Cheese Sticks</td>\n","      <td>21</td>\n","      <td>packaged cheese</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>77</td>\n","      <td>2969</td>\n","    </tr>\n","    <tr>\n","      <th>786403</th>\n","      <td>99578</td>\n","      <td>36216</td>\n","      <td>Lime Italian Sparkling Mineral Water</td>\n","      <td>115</td>\n","      <td>water seltzer sparkling water</td>\n","      <td>7</td>\n","      <td>beverages</td>\n","      <td>Other</td>\n","      <td>36</td>\n","      <td>4076</td>\n","    </tr>\n","    <tr>\n","      <th>786404</th>\n","      <td>99578</td>\n","      <td>2855</td>\n","      <td>Organic Good Seed Bread</td>\n","      <td>112</td>\n","      <td>bread</td>\n","      <td>3</td>\n","      <td>bakery</td>\n","      <td>Other</td>\n","      <td>30</td>\n","      <td>324</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>786405 rows × 10 columns</p>\n","</div>"],"text/plain":["        order_id  product_id                                   product_name  \\\n","0              1       49302                               Bulgarian Yogurt   \n","1              1       11109  Organic 4% Milk Fat Whole Milk Cottage Cheese   \n","2              1       10246                          Organic Celery Hearts   \n","3              1       49683                                 Cucumber Kirby   \n","4              1       43633           Lightly Smoked Sardines in Olive Oil   \n","...          ...         ...                                            ...   \n","786400     99578       38689                       Organic Reduced Fat Milk   \n","786401     99578       47719          Banana Raspberry & Brown Rice Stage 2   \n","786402     99578       17949                     Mild Cheddar Cheese Sticks   \n","786403     99578       36216           Lime Italian Sparkling Mineral Water   \n","786404     99578        2855                        Organic Good Seed Bread   \n","\n","        aisle_id                          aisle  department_id    department  \\\n","0            120                         yogurt             16    dairy eggs   \n","1            108           other creams cheeses             16    dairy eggs   \n","2             83               fresh vegetables              4       produce   \n","3             83               fresh vegetables              4       produce   \n","4             95            canned meat seafood             15  canned goods   \n","...          ...                            ...            ...           ...   \n","786400        84                           milk             16    dairy eggs   \n","786401        92              baby food formula             18        babies   \n","786402        21                packaged cheese             16    dairy eggs   \n","786403       115  water seltzer sparkling water              7     beverages   \n","786404       112                          bread              3        bakery   \n","\n","               type3  product_code  substitute_group  \n","0       Refrigerated            37              4113  \n","1       Refrigerated            68              2948  \n","2       Refrigerated            97              1598  \n","3       Refrigerated            80              1599  \n","4              Other            47               635  \n","...              ...           ...               ...  \n","786400  Refrigerated            68              2539  \n","786401         Other            34               106  \n","786402  Refrigerated            77              2969  \n","786403         Other            36              4076  \n","786404         Other            30               324  \n","\n","[786405 rows x 10 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["data_test_2"]},{"cell_type":"markdown","metadata":{"id":"oBUgQ8sHwOEX"},"source":["## Data analysis should be in this position"]},{"cell_type":"markdown","metadata":{"id":"xrBFUsPtwOEX"},"source":["35,000 products with an order frequency of 10,000 or more (total of 9w orders) - product_id"]},{"cell_type":"markdown","metadata":{"id":"MFsJm2eJwOEY"},"source":["Perform data analysis on data_test_2"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"e3qZE14UwOEY","outputId":"64478243-ec24-4d85-dffa-dda9e627f798"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>order_id</th>\n","      <th>product_id</th>\n","      <th>product_name</th>\n","      <th>aisle_id</th>\n","      <th>aisle</th>\n","      <th>department_id</th>\n","      <th>department</th>\n","      <th>type3</th>\n","      <th>product_code</th>\n","      <th>substitute_group</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>49302</td>\n","      <td>Bulgarian Yogurt</td>\n","      <td>120</td>\n","      <td>yogurt</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>37</td>\n","      <td>4113</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>11109</td>\n","      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n","      <td>108</td>\n","      <td>other creams cheeses</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>68</td>\n","      <td>2948</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>10246</td>\n","      <td>Organic Celery Hearts</td>\n","      <td>83</td>\n","      <td>fresh vegetables</td>\n","      <td>4</td>\n","      <td>produce</td>\n","      <td>Refrigerated</td>\n","      <td>97</td>\n","      <td>1598</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>49683</td>\n","      <td>Cucumber Kirby</td>\n","      <td>83</td>\n","      <td>fresh vegetables</td>\n","      <td>4</td>\n","      <td>produce</td>\n","      <td>Refrigerated</td>\n","      <td>80</td>\n","      <td>1599</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>43633</td>\n","      <td>Lightly Smoked Sardines in Olive Oil</td>\n","      <td>95</td>\n","      <td>canned meat seafood</td>\n","      <td>15</td>\n","      <td>canned goods</td>\n","      <td>Other</td>\n","      <td>47</td>\n","      <td>635</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>786400</th>\n","      <td>99578</td>\n","      <td>38689</td>\n","      <td>Organic Reduced Fat Milk</td>\n","      <td>84</td>\n","      <td>milk</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>68</td>\n","      <td>2539</td>\n","    </tr>\n","    <tr>\n","      <th>786401</th>\n","      <td>99578</td>\n","      <td>47719</td>\n","      <td>Banana Raspberry &amp; Brown Rice Stage 2</td>\n","      <td>92</td>\n","      <td>baby food formula</td>\n","      <td>18</td>\n","      <td>babies</td>\n","      <td>Other</td>\n","      <td>34</td>\n","      <td>106</td>\n","    </tr>\n","    <tr>\n","      <th>786402</th>\n","      <td>99578</td>\n","      <td>17949</td>\n","      <td>Mild Cheddar Cheese Sticks</td>\n","      <td>21</td>\n","      <td>packaged cheese</td>\n","      <td>16</td>\n","      <td>dairy eggs</td>\n","      <td>Refrigerated</td>\n","      <td>77</td>\n","      <td>2969</td>\n","    </tr>\n","    <tr>\n","      <th>786403</th>\n","      <td>99578</td>\n","      <td>36216</td>\n","      <td>Lime Italian Sparkling Mineral Water</td>\n","      <td>115</td>\n","      <td>water seltzer sparkling water</td>\n","      <td>7</td>\n","      <td>beverages</td>\n","      <td>Other</td>\n","      <td>36</td>\n","      <td>4076</td>\n","    </tr>\n","    <tr>\n","      <th>786404</th>\n","      <td>99578</td>\n","      <td>2855</td>\n","      <td>Organic Good Seed Bread</td>\n","      <td>112</td>\n","      <td>bread</td>\n","      <td>3</td>\n","      <td>bakery</td>\n","      <td>Other</td>\n","      <td>30</td>\n","      <td>324</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>786405 rows × 10 columns</p>\n","</div>"],"text/plain":["        order_id  product_id                                   product_name  \\\n","0              1       49302                               Bulgarian Yogurt   \n","1              1       11109  Organic 4% Milk Fat Whole Milk Cottage Cheese   \n","2              1       10246                          Organic Celery Hearts   \n","3              1       49683                                 Cucumber Kirby   \n","4              1       43633           Lightly Smoked Sardines in Olive Oil   \n","...          ...         ...                                            ...   \n","786400     99578       38689                       Organic Reduced Fat Milk   \n","786401     99578       47719          Banana Raspberry & Brown Rice Stage 2   \n","786402     99578       17949                     Mild Cheddar Cheese Sticks   \n","786403     99578       36216           Lime Italian Sparkling Mineral Water   \n","786404     99578        2855                        Organic Good Seed Bread   \n","\n","        aisle_id                          aisle  department_id    department  \\\n","0            120                         yogurt             16    dairy eggs   \n","1            108           other creams cheeses             16    dairy eggs   \n","2             83               fresh vegetables              4       produce   \n","3             83               fresh vegetables              4       produce   \n","4             95            canned meat seafood             15  canned goods   \n","...          ...                            ...            ...           ...   \n","786400        84                           milk             16    dairy eggs   \n","786401        92              baby food formula             18        babies   \n","786402        21                packaged cheese             16    dairy eggs   \n","786403       115  water seltzer sparkling water              7     beverages   \n","786404       112                          bread              3        bakery   \n","\n","               type3  product_code  substitute_group  \n","0       Refrigerated            37              4113  \n","1       Refrigerated            68              2948  \n","2       Refrigerated            97              1598  \n","3       Refrigerated            80              1599  \n","4              Other            47               635  \n","...              ...           ...               ...  \n","786400  Refrigerated            68              2539  \n","786401         Other            34               106  \n","786402  Refrigerated            77              2969  \n","786403         Other            36              4076  \n","786404         Other            30               324  \n","\n","[786405 rows x 10 columns]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["data_test_2 = pd.read_csv('updated_dataset.csv')\n","data_test_2"]},{"cell_type":"markdown","metadata":{"id":"978Z5rZcwOEY"},"source":["## Starting to split the test set and training set.\n","20% test set, 80% training set, randomized by user, 62348 orders, 629914 pieces of data.\n","The remaining test set is 15588 orders, 156491 pieces of data."]},{"cell_type":"code","execution_count":21,"metadata":{"id":"sepbE4xRwOEY"},"outputs":[],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","# Load the dataset\n","data = data_test_2\n","\n","# Get unique order_ids\n","unique_order_ids = data['order_id'].unique()\n","\n","# Split the unique order_ids into train and test\n","train_order_ids, test_order_ids = train_test_split(unique_order_ids, test_size=0.2, random_state=42)\n","\n","# Use these order_ids to split the main dataset into train and test datasets\n","train_data = data[data['order_id'].isin(train_order_ids)]\n","test_data = data[data['order_id'].isin(test_order_ids)]\n","\n","# Save the train and test datasets to CSV files\n","train_data.to_csv('train_dataset.csv', index=False)\n","test_data.to_csv('test_dataset.csv', index=False)\n"]},{"cell_type":"markdown","metadata":{"id":"1aPDHqrawOEZ"},"source":["# Take the training set and train it"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"GCPNI3d6wOEZ"},"outputs":[],"source":["data_train = pd.read_csv('train_dataset.csv')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"wSuwukhnwOEZ"},"outputs":[],"source":["data_test = pd.read_csv('test_dataset.csv')"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["product_id                     21137\n","order_count                     5141\n","product_name    Organic Strawberries\n","type3                          Other\n","Name: 16548, dtype: object"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"id":"yaVgg8KfwOEZ","outputId":"edfc1b49-421f-4734-feba-f4a2cfdf41c3"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>product_id</th>\n","      <th>order_count</th>\n","      <th>product_name</th>\n","      <th>type3</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>24852</td>\n","      <td>9153</td>\n","      <td>Banana</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>9153</th>\n","      <td>13176</td>\n","      <td>7395</td>\n","      <td>Bag of Organic Bananas</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>16548</th>\n","      <td>21137</td>\n","      <td>5141</td>\n","      <td>Organic Strawberries</td>\n","      <td>Other</td>\n","    </tr>\n","    <tr>\n","      <th>21689</th>\n","      <td>21903</td>\n","      <td>4689</td>\n","      <td>Organic Baby Spinach</td>\n","      <td>Refrigerated</td>\n","    </tr>\n","    <tr>\n","      <th>26378</th>\n","      <td>47209</td>\n","      <td>4075</td>\n","      <td>Organic Hass Avocado</td>\n","      <td>Other</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       product_id  order_count            product_name         type3\n","0           24852         9153                  Banana         Other\n","9153        13176         7395  Bag of Organic Bananas         Other\n","16548       21137         5141    Organic Strawberries         Other\n","21689       21903         4689    Organic Baby Spinach  Refrigerated\n","26378       47209         4075    Organic Hass Avocado         Other"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["# Count the number of orders for each product\n","product_counts = data_train['product_id'].value_counts()\n","\n","# Create a dataframe with product_ids and their counts\n","product_popularity = pd.DataFrame({\n","    'product_id': product_counts.index,\n","    'order_count': product_counts.values\n","})\n","\n","# Merge this with the original dataset to get product details\n","product_details = pd.merge(product_popularity, data_train[['product_id', 'product_name', 'type3']], on='product_id', how='left')\n","\n","# Drop duplicates\n","product_details = product_details.drop_duplicates()\n","\n","# Sort products based on their order count\n","product_details_sorted = product_details.sort_values(by='order_count', ascending=False)\n","\n","# Considering constraints: max 100 refrigerated and max 100 frozen\n","ref_count = 0\n","froz_count = 0\n","top_1000_products = pd.DataFrame()\n","for i in range(len(product_details)):\n","    if len(top_1000_products) >= 1000:\n","        break\n","    if product_details_sorted.iloc[i]['type3'] == 'Refrigerated':\n","        if ref_count < 100:\n","            top_1000_products = pd.concat([top_1000_products,product_details_sorted.iloc[[i]]])\n","            ref_count += 1\n","        continue\n","    elif product_details_sorted.iloc[i]['type3'] == 'Frozen':\n","        if froz_count < 100:\n","            top_1000_products = pd.concat([top_1000_products,product_details_sorted.iloc[[i]]])\n","            froz_count += 1\n","        continue\n","    top_1000_products = pd.concat([top_1000_products,product_details_sorted.iloc[[i]]])\n","\n","\n","top_1000_products.head()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"nXCS_Y2dwOEZ","outputId":"8a424a42-4f82-47b5-dfb9-6fc877509c77"},"outputs":[{"data":{"text/plain":["type3\n","Other           800\n","Refrigerated    100\n","Frozen          100\n","Name: count, dtype: int64"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["# Check the number of products in each category within the top 1000 products\n","product_type_counts = top_1000_products['type3'].value_counts()\n","\n","product_type_counts\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of orders using items from the channel: 14162\n","Average % of items from the channel in each order: 45.93%\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the test dataset\n","test_data = pd.read_csv(\"test_dataset.csv\")\n","\n","top_1000_products_id = top_1000_products['product_id'].to_list()\n","# Randomly select 5% of the orders from the test dataset\n","unique_orders = test_data['order_id'].unique()\n","selected_orders = np.random.choice(unique_orders, size=int(0.00 * len(unique_orders)), replace=False)\n","\n","# Replace products in the selected orders with products from the optimized_solution (if they exist)\n","mask = test_data['order_id'].isin(selected_orders)\n","test_data.loc[mask, 'product_id'] = test_data.loc[mask, 'product_id'].apply(lambda x: x if x in top_1000_products_id else np.random.choice(top_1000_products_id))\n","\n","# Calculate the metrics for the modified test dataset\n","orders_with_solution = test_data[test_data['product_id'].isin(top_1000_products_id)]\n","num_orders_with_solution = len(orders_with_solution['order_id'].unique())\n","avg_percentage_items_from_solution = (len(orders_with_solution) / len(test_data)) * 100\n","\n","print(f\"Number of orders using items from the channel: {num_orders_with_solution}\")\n","print(f\"Average % of items from the channel in each order: {avg_percentage_items_from_solution:.2f}%\")"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of orders using items from the channel: 14239\n","Average % of items from the channel in each order: 48.65%\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the test dataset\n","test_data = pd.read_csv(\"test_dataset.csv\")\n","\n","top_1000_products_id = top_1000_products['product_id'].to_list()\n","# Randomly select 5% of the orders from the test dataset\n","unique_orders = test_data['order_id'].unique()\n","selected_orders = np.random.choice(unique_orders, size=int(0.05 * len(unique_orders)), replace=False)\n","\n","# Replace products in the selected orders with products from the optimized_solution (if they exist)\n","mask = test_data['order_id'].isin(selected_orders)\n","test_data.loc[mask, 'product_id'] = test_data.loc[mask, 'product_id'].apply(lambda x: x if x in top_1000_products_id else np.random.choice(top_1000_products_id))\n","\n","# Calculate the metrics for the modified test dataset\n","orders_with_solution = test_data[test_data['product_id'].isin(top_1000_products_id)]\n","num_orders_with_solution = len(orders_with_solution['order_id'].unique())\n","avg_percentage_items_from_solution = (len(orders_with_solution) / len(test_data)) * 100\n","\n","print(f\"Number of orders using items from the channel: {num_orders_with_solution}\")\n","print(f\"Average % of items from the channel in each order: {avg_percentage_items_from_solution:.2f}%\")"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"y-trc-fWwOEa","outputId":"6b065494-2991-4beb-9add-b68880474aec"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 6/10000 [00:00<14:12, 11.73it/s]"]},{"name":"stdout","output_type":"stream","text":["Number of orders using items from the channel: 56480\n","Average % of items from the channel in each order: 45.30%\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","\n","# Load the dataset\n","data = pd.read_csv(\"train_dataset.csv\")\n","\n","# Define the initial state (based on our previous analysis)\n","initial_state = top_1000_products['product_id'].to_list()\n","\n","# Define the cost function\n","def cost(solution):\n","    orders_with_solution = data[data['product_id'].isin(solution)]\n","    num_orders_with_solution = len(orders_with_solution['order_id'].unique())\n","    avg_percentage_items_from_solution = (len(orders_with_solution) / len(data)) * 100\n","    return -1 * (num_orders_with_solution + avg_percentage_items_from_solution)\n","\n","# Define the neighbor function\n","def neighbor(solution):\n","    # Randomly replace one product from the solution with a product not in the solution\n","    product_out = np.random.choice(solution)\n","    product_in = np.random.choice(data[~data['product_id'].isin(solution)]['product_id'].unique())\n","    new_solution = [product_in if x==product_out else x for x in solution]\n","    return new_solution\n","\n","# Simulated Annealing Algorithm\n","def simulated_annealing(initial_solution, T=40, T_min=0.00001, alpha=0.1, max_iterations=10000):\n","    current_solution = initial_solution\n","    current_cost = cost(current_solution)\n","\n","    for i in tqdm(range(max_iterations)):\n","        next_solution = neighbor(current_solution)\n","        next_cost = cost(next_solution)\n","\n","        delta_cost = next_cost - current_cost\n","\n","        if delta_cost > 0 or np.random.uniform(0, 1) < np.exp(delta_cost / T):\n","            current_solution, current_cost = next_solution, next_cost\n","\n","        T = T * alpha\n","        if T < T_min:\n","            break\n","\n","    return current_solution\n","\n","# Run the Simulated Annealing algorithm\n","optimized_solution = simulated_annealing(initial_state)\n","\n","# Calculate the metrics for the optimized solution\n","orders_with_optimized_solution = data[data['product_id'].isin(optimized_solution)]\n","num_orders_with_optimized_solution = len(orders_with_optimized_solution['order_id'].unique())\n","avg_percentage_items_from_optimized_solution = (len(orders_with_optimized_solution) / len(data)) * 100\n","\n","print(f\"Number of orders using items from the channel: {num_orders_with_optimized_solution}\")\n","print(f\"Average % of items from the channel in each order: {avg_percentage_items_from_optimized_solution:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"AJMZ7zuNwOEa"},"source":["optimized_solution：1000的list\n"]},{"cell_type":"markdown","metadata":{"id":"HDODa9JAwOEa"},"source":["Training set: 62,348 orders, 62,914 pieces of data  \n","Test set 15588 orders, 156491 pieces of data  \n","56k was used in the training set with an average utilization of 46%"]},{"cell_type":"markdown","metadata":{"id":"bUZyXN8rwOEa"},"source":["# Tested with a test set and using the 5% alternatives rule"]},{"cell_type":"markdown","metadata":{"id":"NFwl8_4swOEa"},"source":["Results for optimized_solution"]},{"cell_type":"code","execution_count":43,"metadata":{"id":"2Y0qCbspwOEb","outputId":"3ede09e0-95e4-49dc-fbbe-b277bf4c4781"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of orders using items from the channel: 14144\n","Average % of items from the channel in each order: 45.36%\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the test dataset\n","test_data = pd.read_csv(\"test_dataset.csv\")\n","\n","# Randomly select 5% of the orders from the test dataset\n","unique_orders = test_data['order_id'].unique()\n","selected_orders = np.random.choice(unique_orders, size=int(0 * len(unique_orders)), replace=False)\n","\n","# Replace products in the selected orders with products from the optimized_solution (if they exist)\n","mask = test_data['order_id'].isin(selected_orders)\n","test_data.loc[mask, 'product_id'] = test_data.loc[mask, 'product_id'].apply(lambda x: x if x in optimized_solution else np.random.choice(optimized_solution))\n","\n","# Calculate the metrics for the modified test dataset\n","orders_with_solution = test_data[test_data['product_id'].isin(optimized_solution)]\n","num_orders_with_solution = len(orders_with_solution['order_id'].unique())\n","avg_percentage_items_from_solution = (len(orders_with_solution) / len(test_data)) * 100\n","\n","print(f\"Number of orders using items from the channel: {num_orders_with_solution}\")\n","print(f\"Average % of items from the channel in each order: {avg_percentage_items_from_solution:.2f}%\")\n"]},{"cell_type":"markdown","metadata":{"id":"Q_DwJsb9wOEb"},"source":["Training set: 62,348 orders, 62,914 pieces of data  \n","Test set 15588 orders, 156491 pieces of data  \n","14,000 were used in the test set, with an average utilization rate of 49 percent"]},{"cell_type":"markdown","metadata":{"id":"AIG1Jn4gwOEb"},"source":["top_1000_products\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oeUXD1G7wOEb"},"source":["14212\n","Average % of items from the channel in each order: 48.55%"]},{"cell_type":"markdown","metadata":{"id":"pVPyiT25wOEc"},"source":["Training set: 62,348 orders, 62,914 pieces of data  \n","Test set 15588 orders, 156491 pieces of data  \n","14,000 were used in the test set, with an average utilization rate of 48 percent"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of orders using items from the channel: 56550\n","Average % of items from the channel in each order: 45.89%\n"]}],"source":["import pandas as pd\n","import numpy as np\n","\n","# Load the test dataset\n","test_data = pd.read_csv(\"train_dataset.csv\")\n","\n","# Randomly select 5% of the orders from the test dataset\n","unique_orders = test_data['order_id'].unique()\n","selected_orders = np.random.choice(unique_orders, size=int(0 * len(unique_orders)), replace=False)\n","\n","# Replace products in the selected orders with products from the optimized_solution (if they exist)\n","mask = test_data['order_id'].isin(selected_orders)\n","test_data.loc[mask, 'product_id'] = test_data.loc[mask, 'product_id'].apply(lambda x: x if x in top_1000_products_id else np.random.choice(top_1000_products_id))\n","\n","# Calculate the metrics for the modified test dataset\n","orders_with_solution = test_data[test_data['product_id'].isin(top_1000_products_id)]\n","num_orders_with_solution = len(orders_with_solution['order_id'].unique())\n","avg_percentage_items_from_solution = (len(orders_with_solution) / len(test_data)) * 100\n","\n","print(f\"Number of orders using items from the channel: {num_orders_with_solution}\")\n","print(f\"Average % of items from the channel in each order: {avg_percentage_items_from_solution:.2f}%\")\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
